---
title: "LoRA vs. Fine-tuning"
description: ""
date: 2025-04-21T09:00:00+09:00
lastmod:
draft: false
---

Google Geminiによって生成されました。

## 従来のFine-tuning

- 新しいデータセットでの訓練中に、事前学習済みモデルのweightsのすべてまたは大部分を更新する
- モデル全体の知識を対象タスクに適応させることを目的とする
- より計算コストが高く、より多くのデータを必要とする可能性がある

## LoRA (Low-Rank Adaptation)

- 特定のレイヤー内の少数のパラメータセット（rank decomposition matrices）のみを変更する
- 既存の知識を上書きするのではなく、新しい情報を注入することでモデルの動作を適応させることに焦点を当てる
- メモリと訓練時間の点でより効率的

## では、これを"fine-tuning"と呼ぶのは適切か？

- 広義の意味では、そうである。LoRAは事前学習済みモデルを新しいタスクに適応させる技術であり、fine-tuningの一般的な目標と一致している
- ただし、"LoRA fine-tuning"または"fine-tuning with LoRA"と呼ぶのがより正確である。これは従来のfull fine-tuningとは異なることを明確にする。これにより、すべてのweightsを更新するのとは異なる特定の方法を使用していることが明確になる

## 最終的に、用語は柔軟になり得るが、コンテキストを提供することが重要

- LoRAに精通している研究者や実践者の間でLoRAについて議論している場合、単に"fine-tuning"と言うだけで理解される可能性がある
- 他のコンテキストでは、より具体的にして、曖昧さを避け、明確なコミュニケーションを確保するためにLoRAを明示的に言及するのが最善
