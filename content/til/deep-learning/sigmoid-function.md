---
title: 'Sigmoid Function'
description: ''
date: 2024-12-05T9:00:00+09:00
lastmod: 
draft: false
math: true
---

## Sigmoid Function

$ S(x) = \dfrac{1}{1 + e^{ax}} = \dfrac{\tanh(ax/2) + 1}{2} $

Where $ a $ is a gain.

In the context of artificial neural network, the sigmoid function is a synonym for the logistics function.

## Standard Sigmoid Function

$ S(x) = \dfrac{1}{1 + e^x} = \dfrac{\tanh(x/2) + 1}{2} $

Where gain $ a $ is 1.

The inverse of the standard sigmoid function is the logit function.

## References

- [Sigmoid Function - wiki](https://en.m.wikipedia.org/wiki/Sigmoid_function)
