---
title: 'Sigmoid Function'
description: ''
date: 2024-12-05T9:00:00+09:00
lastmod: 
draft: false
math: true
---

## Sigmid function:

$ S(x) = 1 / {1 + e^ax} = {/tanh(ax/2) + 1} / 2 $

Where $ a $ is a gain.

In the context of artificial neural network, the sigmoid function is a synonym for the logistics function.

## Standard sigmoid function:

$ S(x) = 1 / {1 + e^x} = {/tanh(x/2) + 1} / 2 $

Where gain $ a $ is 1.

The inverse of the standard sigmoid function is the logit function.

## References:

- [Sigmoid Function - wiki](https://en.m.wikipedia.org/wiki/Sigmoid_function)