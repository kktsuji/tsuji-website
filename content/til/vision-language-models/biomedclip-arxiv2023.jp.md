---
title: "BiomedCLIP: a multimodal biomedical foundation model pretrained from fifteen million scientific image-text pairs"
description: ""
date: 2024-08-31T8:30:00+09:00
lastmod: 2024-09-01T16:30:00+09:00
draft: false
---

Title: BiomedCLIP: a multimodal biomedical foundation model pretrained from fifteen million scientific image-text pairs

Authors: Sheng Zhang, Yanbo Xu, Naoto Usuyama, Hanwen Xu, Jaspreet Bagga, Robert Tinn, Sam Preston, Rajesh Rao, Mu Wei, Naveen Valluri, Cliff Wong, Andrea Tupini, Yu Wang, Matt Mazzola, Swadheen Shukla, Lars Liden, Jianfeng Gao, Matthew P. Lungren, Tristan Naumann, Sheng Wang, Hoifung Poon

Published: Mar 2, 2023

Link: [https://arxiv.org/abs/2303.00915](https://arxiv.org/abs/2303.00915)

Summary (Generated by Microsoft Copilot):

**Introduction:**

- **BiomedCLIP**は、科学論文からの**1500万の画像テキストペア**で事前学習されたマルチモーダル生物医学基盤モデルであり、生物医学ビジョン言語処理の強化を目指している。

**Challenges:**

- 既存の生物医学データセットは**小規模で多様性に欠け**、胸部X線などの特定の画像タイプに焦点を当てることが多く、汎用性が制限される。

**Methods:**

- **PMC-15M**データセットは、PubMed Centralの**440万の科学論文**から作成され、多様な生物医学画像とキャプションを含む。
- BiomedCLIPは、テキストエンコーディングにPubMedBERT、画像エンコーディングにVision Transformerモデルなどの**ドメイン固有の適応**を使用する。

**Novelties:**

- これまでで**最大の生物医学マルチモーダルデータセット**であり、以前のデータセットよりも大幅に大きく、より多様である。
- テキストと画像処理の両方のための**ドメイン固有の適応**。

**Results:**

- BiomedCLIPは、クロスモーダル検索、画像分類、視覚的質問応答を含む様々な生物医学タスクで**最先端のパフォーマンス**を達成した。

**Performances:**

- **低リソース設定**でも、一般ドメインモデルや以前の生物医学モデルを上回った。

**Limitations:**

- **複合図**はサブ図に分割されていない。
- **計算上の制約**により、より大きなモデルとより高い画像解像度の探索が制限された。

**Discussion:**

- BiomedCLIPは、生物医学ビジョン言語モデルのための**大規模で多様な事前学習の重要性**を示し、将来の研究と応用への道を開く。
