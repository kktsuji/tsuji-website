---
title: "Towards a Visual-Language Foundation Model for Computational Pathology"
description: ""
date: 2024-08-30T8:30:00+09:00
lastmod: 2024-09-01T16:30:00+09:00
draft: false
---

Title: Towards a Visual-Language Foundation Model for Computational Pathology

Authors: Ming Y. Lu, Bowen Chen, Drew F. K. Williamson, Richard J. Chen, Ivy Liang, Tong Ding, Guillaume Jaume, Igor Odintsov, Andrew Zhang, Long Phi Le, Georg Gerber, Anil V Parwani, Faisal Mahmood

Published: Jul 24, 2023

Link: [https://arxiv.org/abs/2307.12914](https://arxiv.org/abs/2307.12914)

Summary (Generated by Microsoft Copilot):

**Introduction:**

- この論文は、117万以上の画像キャプションペアを使用して開発された、病理組織学のためのビジュアル言語基盤モデルであるCONCHを紹介する。

**Challenges:**

- 医療分野におけるラベルの不足と、データ収集とアノテーションの労力集約的なプロセス。

**Methods:**

- コントラスト学習とキャプション生成の目的を利用して事前学習を行い、多様な病理組織画像と生物医学テキストを活用する。

**Novelties:**

- CONCHは、タスク固有のトレーニングデータなしで、zero-shot分類、セグメンテーション、検索タスクを実行する能力を持つ。

**Results:**

- 病理組織画像の分類やセグメンテーションを含む13の多様なベンチマークで、最先端のパフォーマンスを達成する。

**Performances:**

- PLIPやBiomedCLIPなどの他のモデルを、様々なタスクで大幅に上回る。

**Limitations:**

- 事前学習データの規模が一般的なビジュアル言語モデルと比較して小さく、zero-shot認識能力が制限される。

**Discussion:**

- CONCHは、トレーニング例のアノテーションの負担を軽減し、臨床環境での検索能力を向上させる可能性を強調している。
