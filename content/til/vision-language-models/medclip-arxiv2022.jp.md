---
title: "MedCLIP: Contrastive Learning from Unpaired Medical Images and Text"
description: ""
date: 2024-09-01T16:30:00+09:00
lastmod:
draft: false
---

Title: MedCLIP: Contrastive Learning from Unpaired Medical Images and Text

Authors: Zifeng Wang, Zhenbang Wu, Dinesh Agarwal, Jimeng Sun

Published: Oct 18, 2022

Link: [https://arxiv.org/abs/2210.10163](https://arxiv.org/abs/2210.10163)

Summary (Generated by Microsoft Copilot):

**Introduction:**

- MedCLIPは、画像とテキストを分離することで、ペアになっていない医療画像テキストデータセットの限界に対処し、マルチモーダルコントラスト学習を実現する。

**Challenges:**

- **データ不足:** 医療画像テキストデータセットは、一般的なデータセットよりもはるかに小さい。
- **False Negatives:** 意味的に類似した別の患者の画像とレポートが、誤ってネガティブとして扱われる。

**Methods:**

- **画像とテキストの分離:** ペアになっていないデータセットを利用して、トレーニングデータを拡大する。
- **セマンティックマッチング損失:** 医学知識を使用してfalse negativesを排除する。

**Novelties:**

- ペアになっていない画像とテキストを組み合わせて、トレーニングデータを拡大する。
- 医学知識に基づくセマンティックマッチング損失を導入する。

**Results:**

- zero-shot予測、教師あり分類、画像テキスト検索において、最先端の手法を上回る。

**Performances:**

- 他の手法と比較して、大幅に少ない事前学習データで優れた精度を達成する。

**Limitations:**

- 不正確なセマンティックタグや、否定や不確実性のフレーズの検出漏れの課題がある。

**Discussion:**

- MedCLIPは、高いデータ効率性と様々な下流タスクへの転移可能性を示し、医療診断のための基盤モデルをサポートする。
