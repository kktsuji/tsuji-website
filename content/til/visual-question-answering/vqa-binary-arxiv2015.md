---
title: 'Yin and Yang: Balancing and Answering Binary Visual Questions'
description: ''
date: 2024-09-07T15:15:00+09:00
lastmod: 
draft: false
---

Title: Yin and Yang: Balancing and Answering Binary Visual Questions

Authors: Peng Zhang, Yash Goyal, Douglas Summers-Stay, Dhruv Batra, Devi Parikh

Published: Nov 16 2015

Link: [https://arxiv.org/abs/1511.05099](https://arxiv.org/abs/1511.05099)

Summary (Generated by Microsoft Copilot):

**Introduction:**
- The paper addresses binary Visual Question Answering (VQA) on abstract scenes, focusing on visual verification of concepts inquired in questions.

**Challenges:**
- Language priors can lead to superficial performance without true visual understanding.
- Dataset biases can hinder progress in multi-modal AI.

**Methods:**
- Convert questions into tuples summarizing visual concepts.
- Use abstract scenes to balance the dataset, ensuring equal "yes" and "no" answers for each question.

**Novelties:**
- Balanced dataset creation with complementary scenes.
- Tuple extraction for concise visual concept representation.

**Results:**
- Language-only models perform poorly on the balanced dataset.
- Proposed approach matches state-of-the-art performance on unbalanced datasets and outperforms on balanced datasets.

**Performances:**
- Significant improvement in visual reasoning and understanding.
- Better performance by attending to relevant image regions.

**Limitations:**
- Some scenes cannot be modified due to limited clipart library.
- Handling negative questions remains challenging.

**Discussion:**
- Balancing datasets can improve visual understanding.
- Future work should focus on detailed visual semantics and real images.
